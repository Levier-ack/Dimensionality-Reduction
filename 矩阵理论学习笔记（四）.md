# 降维

矩阵降维后可以用更小规模的矩阵表示原矩阵，且不改变原矩阵的特征。在主成分分析（PCA）中，分析特征值和特征值的使用。本文介绍奇异值分解（SVD），一种比UV分解更强大的分解。然后在SVD的基础上介绍它的变种，CUR分解，CUR分解可以在原矩阵是稀疏时，保持分解后矩阵的稀疏性的分解方式。

## 基础概念

### 奇异矩阵

方阵$A$的秩不是满秩，则$A$是奇异矩阵。

1. 可逆矩阵是非奇异矩阵，非奇异矩阵也是可逆矩阵。
2. 如果$A$为奇异矩阵，则$Ax=0$有无穷解，$Ax=b$有无穷解或者无解。
3. 如果$A$为非奇异矩阵，则$Ax=0$有且只有唯一0解，$Ax=b$有唯一解。

### 正定矩阵

1. 一个矩阵半正定当且仅当它的每个特征值大于或者等于0。
2. 一个矩阵正定当且仅当它的每个特征值都大于0。

### 向量范数

1. 非负性：$||x||\geq 0$
2. 齐次性：$||ax||=|a|·||x||$
3. 三角不等式：$||x||+||y||\geq ||x+y||$
4. 1-范数：$||x||_1=|x_1|+|x_2|+...+|x_n|=\sum_{i=1}^n|x_i|$
5. 2-范数（Euclidean范数）：$||x||_2=\sqrt{x_1^2+x_2^2+...+x_n^2}=(\sum_{i=1}^2x_i^2)^\frac{1}{2}$
6. 无穷范数：$||x||_\infty=max(|x_1|,|x_2|,...,|x_n|)$

### 矩阵范数

如果满足范数三条件，同时满足矩阵乘法相容性（次乘性）：$||A||\cdot||B||\geq ||A\cdot B||$

1. 列和范数（1-范数）：$||A||_1=max_{1\leq j\leq n}(\sum_{i=1}^m|a_{ij}|)$
2. 行和范数（$\infty$-范数）：$||A||_\infty=max_{1\leq m}(\sum_{j=1}^n|a_{ij}|)$
3. Frobenius范数（F-范数）：$||A||_F=(\sum_{i=1}^m\sum_{j=1}^n|a_{ij}|^2)^\frac{1}{2}$
4. 2-范数（谱模）：$||A||_2=\sqrt{\lambda_{max}(A^TA)}$，矩阵$A^TA$的最大特征值开平方根。

## 特征值和特征向量

### 定义

设定$M$为一个方阵，设定$\lambda$为一个常数，$e$是一个非零列向量，和$M$的行数相同，那么称$\lambda$为$M$的特征值，$e$为$M$的特征向量。如果$e$是$M$的特征向量，$c$是任意常数，那么$ce$也是一个$M$的特征向量，且有相同的特征值。向量乘以一个常量只改变向量的长度，不改变向量的方向，因此为了避免长度的不同，规定单位向量，意味着**向量每个元素的平方和为1**.为了防止出现乘以-1的情况，我们要求特征向量的第一个非零分量为正。

![image-20210604104141264](D:\大数据系统分析\Dimensionality-Reduction-main\矩阵理论学习笔记（四）.assets\image-20210604104141264.png)

### 计算特征值和特征向量

1. 幂迭代法

   等待更新

2. 行列式为0

   由$Me=\lambda e$，可得$(M-\lambda I)e=0$

   即$M-\lambda I=0$

   该行列式为$n$次，因此有$n$个解，从
